# Health Insurance Cross Sell Prediction 游 游낀

## Autores

Josep Riballo Moreno y Pau Leyva Garc칤a 

## Contexto

Este proyecto aborda el desaf칤o de predecir si los asegurados de una compa침칤a de seguros de salud estar치n interesados en adquirir tambi칠n un seguro de veh칤culo. Este modelo es clave para optimizar las estrategias de comunicaci칩n y maximizar los ingresos al contactar de manera efectiva a los clientes interesados.

Las p칩lizas de seguro operan bajo el concepto de compartir riesgos entre un grupo de clientes. Por ejemplo, los costos de hospitalizaci칩n pueden ser cubiertos a trav칠s de las primas regulares que pagan los asegurados. Este principio se aplica tanto al seguro de salud como al de veh칤culos, donde la prima asegura la cobertura de costos en caso de accidentes.

Dado este contexto, la predicci칩n precisa de clientes interesados en el seguro de veh칤culo permitir치 a la empresa optimizar sus esfuerzos de marketing y alcanzar sus objetivos de negocio.

---

## Descripci칩n del Dataset

El conjunto de datos, obtenido de [Kaggle](https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction), contiene informaci칩n demogr치fica, de veh칤culo y p칩lizas de seguro. Las variables principales son:

| **Variable**            | **Descripci칩n**                                                             |
|--------------------------|-----------------------------------------------------------------------------|
| **id**                  | ID 칰nico para el cliente                                                   |
| **Gender**              | G칠nero del cliente                                                        |
| **Age**                 | Edad del cliente                                                          |
| **Driving_License**     | 0: Sin licencia de conducir, 1: Con licencia de conducir                   |
| **Region_Code**         | C칩digo 칰nico para la regi칩n del cliente                                    |
| **Previously_Insured**  | 1: Ya tiene seguro de veh칤culo, 0: No tiene seguro                         |
| **Vehicle_Age**         | Edad del veh칤culo                                                         |
| **Vehicle_Damage**      | 1: Ha sufrido da침os en el pasado, 0: No ha tenido da침os                    |
| **Annual_Premium**      | Prima anual pagada por el cliente                                          |
| **Policy_Sales_Channel**| Canal utilizado para la captaci칩n del cliente                              |
| **Vintage**             | D칤as que el cliente lleva asociado a la compa침칤a                          |
| **Response**            | 1: Cliente interesado, 0: Cliente no interesado                           |

---

## Proceso del Proyecto

### 1. An치lisis Exploratorio de Datos (EDA)

Se realiz칩 una revisi칩n exhaustiva del dataset para identificar patrones y relaciones clave:
- **Distribuci칩n de clases:** Fuerte desbalance entre clientes interesados (`Response=1`) y no interesados (`Response=0`).
- **Valores nulos:** No se encontraron valores nulos.
- **Transformaciones:** Se realizaron escalados y codificaci칩n de variables categ칩ricas (`Gender`, `Vehicle_Age`, `Vehicle_Damage`) para su uso en los modelos.

---

### 2. T칠cnicas de Balanceo

Dado el desbalance en la variable objetivo (`Response`), se aplic칩 la t칠cnica **SMOTE** (Synthetic Minority Oversampling Technique) para generar muestras sint칠ticas de la clase minoritaria (`1`). Esto permiti칩 mejorar el aprendizaje del modelo al equilibrar las proporciones de ambas clases.

---

### 3. Modelos Probados

Se evaluaron tres modelos principales con sus respectivas optimizaciones:

#### **3.1. Regresi칩n Log칤stica**
Modelo base utilizado para comparar resultados.
- Buen desempe침o en **accuracy** general (87.50% en validaci칩n).
- Bajo desempe침o en la detecci칩n de la clase minoritaria (`1`), con valores casi nulos en recall y f1-score sin oversampling.
- Mejora con SMOTE, pero sigue siendo inferior a los modelos basados en 치rboles.

#### **3.2. Random Forest**
Modelo de 치rboles que captura relaciones no lineales.
- Desempe침o inicial con **AUC-ROC** de 0.8639 en validaci칩n.
- Optimizaci칩n de hiperpar치metros mejor칩 el **AUC-ROC** a 0.9037.
- Mejor balance entre recall y precisi칩n en la clase `1`, sacrificando algo de precisi칩n en la clase `0`.

#### **3.3. XGBoost**
Modelo basado en boosting, altamente eficiente.
- **AUC-ROC** de 0.8981 en validaci칩n tras optimizaci칩n.
- Excelente **recall** (98%) en la clase `1`, lo que garantiza la detecci칩n de casi todos los clientes interesados.
- Sacrificio en precisi칩n en la clase `0`, generando falsos positivos.

---

### 4. Resultados y Comparativa

| M칠trica       | Regresi칩n Log칤stica (SMOTE) | Random Forest (Optimizado) | XGBoost (Optimizado) |
|---------------|-----------------------------|----------------------------|-----------------------|
| **AUC-ROC (Val)** | 0.8353                      | 0.9037                     | 0.8981                |
| **Recall (Clase 1)** | 87%                         | 97%                        | 98%                   |
| **Precision (Clase 1)** | 45%                         | 75%                        | 74%                   |
| **Accuracy (Val)** | 87.50%                      | 79.27%                     | 81.49%                |

---

### 5. Recomendaciones

En funci칩n de los resultados obtenidos:
- **Random Forest**: Recomendado si se busca un balance entre precisi칩n y recall en ambas clases.
- **XGBoost**: Ideal si el objetivo es maximizar el recall en la clase `1` (clientes interesados), cumpliendo el objetivo de minimizar falsos negativos.

#### **Ajustes adicionales seg칰n la estrategia de negocio:**
- Modificar el umbral (**threshold**) para ajustar el balance entre falsos positivos y recall.
- Considerar modelos h칤bridos o estrategias combinadas si los falsos positivos generan un alto impacto operativo.

---

## Uso del Proyecto

### **Requisitos**
1. **Python 3.8+**
2. Librer칤as requeridas: `numpy`, `pandas`, `matplotlib`, `seaborn`, `scikit-learn`, `xgboost`, `imblearn`.

### **Instrucciones**
1. Clonar el repositorio:  
   ```bash
   git clone https://github.com/Leyva03/cas_kaggle_health
   ```
2. Instalar las dependencias:  
   ```bash
   pip install -r requirements.txt
   ```
3. Ejecutar el notebook:

### **Archivos Principales**
- `CasKaggle.ipynb`: Script principal que implementa el flujo del proyecto.
- `train.csv`, `test.csv`: Datasets de entrenamiento y prueba.
- `README.md`: Detalles del proyecto.
- `requirements.txt`: Dependencias del proyecto.

---

## Conclusi칩n

El modelo **XGBoost optimizado** es el m치s adecuado para este caso, ya que prioriza la detecci칩n de clientes interesados (recall de 98%). Dependiendo de la estrategia de negocio, ajustes en el umbral o combinaciones de modelos pueden reducir los falsos positivos, maximizando la efectividad de las campa침as de marketing.